{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 : Data Collection in the Wild [4 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/LAKSH_LAYING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/LAKSH_SITTING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/LAKSH_STANDING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/LAKSH_WALKING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/LAKSH_WALKING_DOWNSTAIRS.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/LAKSH_WALKING_UPSTAIRS.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/RUDRA_LAYING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/RUDRA_SITTING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/RUDRA_STANDING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/RUDRA_WALKING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/RUDRA_WALKING_DOWNSTAIRS.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/RUDRA_WALKING_UPSTAIRS.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/PARTHIV_LAYING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/PARTHIV_SITTING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/PARTHIV_STANDING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/PARTHIV_WALKING.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/PARTHIV_WALKING_DOWNSTAIRS.csv\n",
      "Checking file: /Users/na/Machine Learning Assignment/Assignment-1_Task_2/ES335-assignment-1/HAR/task4/PARTHIV_WALKING_UPSTAIRS.csv\n",
      "Data merging complete. The combined dataset (first 500 rows) has been created and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define subjects\n",
    "subjects = ['LAKSH', 'RUDRA', 'PARTHIV']\n",
    "\n",
    "# Define activities\n",
    "\n",
    "activities = ['LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS', 'WALKING_UPSTAIRS']\n",
    "\n",
    "# Function to load the first 500 rows of each dataset\n",
    "def load_data(subjects, activities):\n",
    "    data_list = []\n",
    "    for subject in subjects:\n",
    "        for activity in activities:\n",
    "            file_name = f\"{subject}_{activity}.csv\"\n",
    "            file_path = os.path.join(os.getcwd(), file_name)\n",
    "            print(f\"Checking file: {file_path}\")  # Debugging line\n",
    "            if os.path.exists(file_path):\n",
    "                # Read the first 500 rows\n",
    "                df = pd.read_csv(file_path, nrows=500)\n",
    "                df['Activity'] = activity\n",
    "                df['Subject'] = subject\n",
    "                data_list.append(df)\n",
    "            else:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "    return pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Load and process data\n",
    "combined_data_df = load_data(subjects, activities)\n",
    "\n",
    "# Save combined DataFrame to CSV if needed\n",
    "combined_data_df.to_csv('combined_taken_data.csv', index=False)\n",
    "\n",
    "print(\"Data merging complete. The combined dataset (first 500 rows) has been created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>gFx</th>\n",
       "      <th>gFy</th>\n",
       "      <th>gFz</th>\n",
       "      <th>TgF</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010562</td>\n",
       "      <td>0.3288</td>\n",
       "      <td>-0.3991</td>\n",
       "      <td>-0.8522</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036925</td>\n",
       "      <td>0.3302</td>\n",
       "      <td>-0.4017</td>\n",
       "      <td>-0.8520</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.3319</td>\n",
       "      <td>-0.4014</td>\n",
       "      <td>-0.8506</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058767</td>\n",
       "      <td>0.3346</td>\n",
       "      <td>-0.4027</td>\n",
       "      <td>-0.8482</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092472</td>\n",
       "      <td>0.3361</td>\n",
       "      <td>-0.4061</td>\n",
       "      <td>-0.8498</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>10.036258</td>\n",
       "      <td>0.6290</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>0.67</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>PARTHIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>10.062572</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>0.68</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>PARTHIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>10.079894</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.73</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>PARTHIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>10.097549</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.78</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>PARTHIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>10.115518</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.83</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>PARTHIV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time     gFx     gFy     gFz   TgF          Activity  Subject\n",
       "0      0.010562  0.3288 -0.3991 -0.8522  1.00            LAYING    LAKSH\n",
       "1      0.036925  0.3302 -0.4017 -0.8520  1.00            LAYING    LAKSH\n",
       "2      0.042296  0.3319 -0.4014 -0.8506  1.00            LAYING    LAKSH\n",
       "3      0.058767  0.3346 -0.4027 -0.8482  1.00            LAYING    LAKSH\n",
       "4      0.092472  0.3361 -0.4061 -0.8498  1.00            LAYING    LAKSH\n",
       "...         ...     ...     ...     ...   ...               ...      ...\n",
       "8995  10.036258  0.6290  0.1049  0.2126  0.67  WALKING_UPSTAIRS  PARTHIV\n",
       "8996  10.062572  0.6412  0.0711  0.2192  0.68  WALKING_UPSTAIRS  PARTHIV\n",
       "8997  10.079894  0.6825  0.1017  0.2325  0.73  WALKING_UPSTAIRS  PARTHIV\n",
       "8998  10.097549  0.7275  0.1801  0.2133  0.78  WALKING_UPSTAIRS  PARTHIV\n",
       "8999  10.115518  0.7751  0.2434  0.1575  0.83  WALKING_UPSTAIRS  PARTHIV\n",
       "\n",
       "[9000 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>gFx</th>\n",
       "      <th>gFy</th>\n",
       "      <th>gFz</th>\n",
       "      <th>TgF</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092472</td>\n",
       "      <td>0.3361</td>\n",
       "      <td>-0.4061</td>\n",
       "      <td>-0.8498</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109648</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>-0.4076</td>\n",
       "      <td>-0.8547</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127517</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>-0.4095</td>\n",
       "      <td>-0.8591</td>\n",
       "      <td>1.01</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141784</td>\n",
       "      <td>0.3293</td>\n",
       "      <td>-0.4107</td>\n",
       "      <td>-0.8542</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158437</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>-0.4079</td>\n",
       "      <td>-0.8498</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>9.989899</td>\n",
       "      <td>0.3342</td>\n",
       "      <td>-0.4042</td>\n",
       "      <td>-0.8517</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>10.007281</td>\n",
       "      <td>0.3339</td>\n",
       "      <td>-0.4042</td>\n",
       "      <td>-0.8501</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>10.025262</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>-0.4024</td>\n",
       "      <td>-0.8491</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>10.041070</td>\n",
       "      <td>0.3366</td>\n",
       "      <td>-0.4035</td>\n",
       "      <td>-0.8496</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>10.064506</td>\n",
       "      <td>0.3354</td>\n",
       "      <td>-0.4032</td>\n",
       "      <td>-0.8489</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>LAKSH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time     gFx     gFy     gFz   TgF Activity Subject\n",
       "0     0.092472  0.3361 -0.4061 -0.8498  1.00   LAYING   LAKSH\n",
       "1     0.109648  0.3321 -0.4076 -0.8547  1.00   LAYING   LAKSH\n",
       "2     0.127517  0.3305 -0.4095 -0.8591  1.01   LAYING   LAKSH\n",
       "3     0.141784  0.3293 -0.4107 -0.8542  1.00   LAYING   LAKSH\n",
       "4     0.158437  0.3290 -0.4079 -0.8498  1.00   LAYING   LAKSH\n",
       "..         ...     ...     ...     ...   ...      ...     ...\n",
       "488   9.989899  0.3342 -0.4042 -0.8517  1.00   LAYING   LAKSH\n",
       "489  10.007281  0.3339 -0.4042 -0.8501  1.00   LAYING   LAKSH\n",
       "490  10.025262  0.3351 -0.4024 -0.8491  1.00   LAYING   LAKSH\n",
       "491  10.041070  0.3366 -0.4035 -0.8496  1.00   LAYING   LAKSH\n",
       "492  10.064506  0.3354 -0.4032 -0.8489  1.00   LAYING   LAKSH\n",
       "\n",
       "[493 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the unique subjects and activities\n",
    "subjects = combined_data_df['Subject'].unique()\n",
    "activities = combined_data_df['Activity'].unique()\n",
    "\n",
    "# Initialize an empty DataFrame to store the trimmed data\n",
    "trimmed_combined_data_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each subject\n",
    "for subject in subjects:\n",
    "    # Filter data for the current subject\n",
    "    subject_data = combined_data_df[combined_data_df['Subject'] == subject]\n",
    "    \n",
    "    # Iterate over each activity\n",
    "    for activity in activities:\n",
    "        # Filter data for the current activity of the current subject\n",
    "        activity_data = subject_data[subject_data['Activity'] == activity]\n",
    "        \n",
    "        # Calculate total duration\n",
    "        total_duration = activity_data['time'].iloc[-1] - activity_data['time'].iloc[0]\n",
    "        desired_duration = 10\n",
    "        trim_duration = (total_duration - desired_duration) / 2\n",
    "        \n",
    "        # Calculate start and end times for trimming\n",
    "        st = activity_data['time'].iloc[0] + trim_duration\n",
    "        et = activity_data['time'].iloc[-1] - trim_duration\n",
    "        \n",
    "        # Trim the data for the current activity and subject\n",
    "        trimmed_data = activity_data[(activity_data['time'] >= st) & (activity_data['time'] <= et)]\n",
    "        \n",
    "        # Append the trimmed data to the main DataFrame\n",
    "        trimmed_combined_data_df = pd.concat([trimmed_combined_data_df, trimmed_data])\n",
    "\n",
    "# Assign the trimmed DataFrame back to combined_data_df\n",
    "combined_data_df = trimmed_combined_data_df.reset_index(drop=True)\n",
    "\n",
    "# Print the final trimmed DataFrame\n",
    "display(combined_data_df[(combined_data_df['Subject']=='LAKSH') & (combined_data_df['Activity']=='LAYING')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use the Decision Tree model trained on the UCI-HAR dataset to predict the activities that you performed. Report the accuracy, precision, recall and confusion matrix of the model. You have three version of UCI dataset you can use a)Raw data from accelerometer, b)TSFEL featurised data, c)Features provided by author. Choose which version to use, ensuring that your test data is similar to your training data. How did the model perform? **[1 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (126, 500, 3)\n",
      "Testing data shape:  (54, 500, 3)\n",
      "Training output data shape:  (126,)\n",
      "Testing output data shape:  (54,)\n",
      "accuracy:  0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "curr_dir = os.getcwd()\n",
    "working_dir = os.path.join(curr_dir , \"..\")\n",
    "os.chdir(working_dir)\n",
    "\n",
    "from Dataset.MakeDataset import X,y\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# print(X)\n",
    "X = X.mean(axis=1)\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=7)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=20,stratify=y)\n",
    "dt.fit(X_train, y_train)\n",
    "y_predicted = dt.predict(X_test)\n",
    "y_predicted = pd.DataFrame({'Label':y_predicted})\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "precision = precision_score(y_test, y_predicted, average='weighted')\n",
    "recall = recall_score(y_test, y_predicted, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.18422535211267604\n"
     ]
    }
   ],
   "source": [
    "X = combined_data_df.iloc[:,1:4]\n",
    "# X = X.sample()\n",
    "y = combined_data_df.iloc[:,-2]\n",
    "# print(X)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "y_predict = dt.predict(X_test)\n",
    "y_test = np.array(y_test)\n",
    "activities = ['LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS', 'WALKING_UPSTAIRS']\n",
    "\n",
    "\n",
    "y_predict_new = []\n",
    "for i in range(len(y_predict)):\n",
    "\ty_predict_new.append(activities[y_predict[i]-1])\n",
    "\n",
    "# print(y_predict)\n",
    "y_predict = np.array(y_predict_new)\n",
    "accuracy = 0\n",
    "for i in range(len(y_predict)):\n",
    "\tif y_predict[i]==y_test[i]:\n",
    "\t\taccuracy +=1\n",
    "accuracy = accuracy/len(y_test)\n",
    "print('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the data you collected to predict the activities that you performed. Decide whether to apply preprocessing and featurization, and if so, choose the appropriate methods. How did the model perform? **[1 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.84507042253522\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "X_train = combined_data_df.iloc[:,0:-2]\n",
    "y_train = combined_data_df.iloc[:,-2]\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=42)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_predict = dt.predict(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "accuracy = 0\n",
    "for i in range(len(y_test)):\n",
    "    if (y_test[i]==y_predict[i]):\n",
    "        accuracy +=1\n",
    "\n",
    "accuracy = accuracy*100/len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Leaking Subject data in Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  43.948613928329955\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "combined_data_df_by_subject_train = combined_data_df[(combined_data_df['Subject']=='PARTHIV') | (combined_data_df['Subject']=='LAKSH')] \n",
    "combined_data_df_by_subject_test = combined_data_df[(combined_data_df['Subject']=='RUDRA')] \n",
    "\n",
    "\n",
    "X_train = combined_data_df_by_subject_train.iloc[:,0:-2]\n",
    "y_train = combined_data_df_by_subject_train.iloc[:,-2]\n",
    "X_test = combined_data_df_by_subject_test.iloc[:,0:-2]\n",
    "y_test = combined_data_df_by_subject_test.iloc[:,-2]\n",
    "# print(X)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=42)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=7)\n",
    "dt.fit(X_train, y_train)\n",
    "y_predict = dt.predict(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "accuracy = 0\n",
    "for i in range(len(y_test)):\n",
    "    if (y_test[i]==y_predict[i]):\n",
    "        accuracy +=1\n",
    "\n",
    "accuracy = accuracy*100/len(y_test)\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/9gqwdgkj59zg8_vc_s8h33200000gn/T/ipykernel_15735/1998554677.py:14: UserWarning: Using default sampling frequency set in configuration file.\n",
      "  features = tsfel.time_series_features_extractor(cfg_file, X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='67'\n",
       "                  max='67',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  67\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Feature extraction finished ***\n",
      "accuracy:  15.492957746478874\n"
     ]
    }
   ],
   "source": [
    "import tsfel\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming X and y are already loaded as pandas DataFrames or NumPy arrays\n",
    "\n",
    "# If y is not DataFrames, convert them\n",
    "y = pd.DataFrame(y, columns=['Target'])\n",
    "\n",
    "# Feature extraction with TSFEL\n",
    "cfg_file = tsfel.get_features_by_domain()  # Use default configuration file\n",
    "features = tsfel.time_series_features_extractor(cfg_file, X)\n",
    "\n",
    "# Concatenate the extracted features with the target variable\n",
    "features_with_target = pd.concat([features, y], axis=1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_with_target.drop(columns='Target'), features_with_target['Target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Decision Tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "y_test\n",
    "\n",
    "accuracy = 0\n",
    "for i in range(len(y_test)):\n",
    "    if (y_test[i]==y_pred[i]):\n",
    "        accuracy +=1\n",
    "\n",
    "accuracy = accuracy*100/len(y_test)\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSFEL is giving less result than original dataset therefore there is no need of featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Few-Shot prompting method using UCI-HAR dataset to predict the activities that you performed. Ensure that both your examples and test query undergo similar preprocessing. How did the model perform? **[1 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "model_name = os.getenv(\"MODEL_NAME\")\n",
    "\n",
    "groq_models = {\n",
    "    \"llama3-70b\": \"llama3-70b-8192\",\n",
    "    \"mixtral\": \"mixtral-8x7b-32768\",\n",
    "    \"gemma-7b\": \"gemma-7b-it\",\n",
    "    \"llama3.1-70b\": \"llama-3.1-70b-versatile\",\n",
    "    \"llama3-8b\": \"llama3-8b-8192\",\n",
    "    \"llama3.1-8b\": \"llama-3.1-8b-instant\",\n",
    "    \"gemma-9b\": \"gemma2-9b-it\"\n",
    "}\n",
    "llm = ChatGroq(model=groq_models[model_name] , api_key=groq_api_key, temperature=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">TRAINED ON GIVEN DATASET, TESTED ON COLLECTED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYING LAYING\n",
      "1\n",
      "SITTING STANDING\n",
      "STANDING STANDING\n",
      "2\n",
      "WALKING WALKING\n",
      "3\n",
      "WALKING_DOWNSTAIRS WALKING\n",
      "WALKING_UPSTAIRS WALKING\n",
      "LAYING LAYING\n",
      "4\n",
      "SITTING STANDING\n",
      "STANDING STANDING\n",
      "5\n",
      "WALKING WALKING_UPSTAIRS\n",
      "WALKING_DOWNSTAIRS WALKING_UPSTAIRS\n",
      "WALKING_UPSTAIRS WALKING_UPSTAIRS\n",
      "6\n",
      "LAYING LAYING\n",
      "7\n",
      "SITTING STANDING\n",
      "STANDING STANDING\n",
      "8\n",
      "WALKING WALKING\n",
      "9\n",
      "WALKING_DOWNSTAIRS WALKING\n",
      "WALKING_UPSTAIRS WALKING\n",
      "Classification complete. Results have been saved to 'model_predictions.csv'.\n",
      "accuracy 50.0\n"
     ]
    }
   ],
   "source": [
    "curr_dir = os.getcwd()\n",
    "working_dir = os.path.join(curr_dir , \"..\",\"task4\")\n",
    "os.chdir(working_dir)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the test data loaded as a DataFrame\n",
    "test_data_df = pd.read_csv('combined_taken_data.csv')\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "# Define the activities\n",
    "activities = ['LAYING', 'STANDING', 'WALKING', 'SITTING', 'WALKING UPSTAIRS', 'WALKING DOWNSTAIRS']\n",
    "\n",
    "def sample_data(data, sample_rate=10):\n",
    "    n=500//sample_rate\n",
    "    return data[100:n+100]\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Filter training data for specific subjects\n",
    "train_subjects = [1, 3, 5, 7]\n",
    "train_data_df = pd.read_csv('train_data_combined.csv')\n",
    "train_data_df = train_data_df[train_data_df['Subject'].isin(train_subjects)]\n",
    "\n",
    "# Iterate through each group by subject and activity\n",
    "for (subject, activity), group in test_data_df.groupby(['Subject', 'Activity']):\n",
    "    # Sample data\n",
    "    accx = sample_data(group['gFx'].tolist())\n",
    "    accy = sample_data(group['gFy'].tolist())\n",
    "    accz = sample_data(group['gFz'].tolist())\n",
    "    \n",
    "    # Create prompt for the current group\n",
    "    query_few_shot_Task4 = f\"\"\"\n",
    "    * You are a highly accurate activity classification model.\n",
    "    * Your task is to classify human activities based on the given accelerometer data.\n",
    "    * The accelerometer data is provided as mean acceleration values in the x, y, and z directions.\n",
    "    * You are given data corresponding to six different activities.\n",
    "    * The possible activities to classify are: LAYING, STANDING, WALKING, SITTING, WALKING UPSTAIRS, and WALKING DOWNSTAIRS.\"\"\"\n",
    "\n",
    "    for (train_subject, train_activity), grp in train_data_df.groupby(['Subject', 'Activity']):\n",
    "        query_few_shot_Task4 += \"\"\"Here are some examples of accelerometer data and their corresponding activities:\"\"\"\n",
    "\n",
    "        query_few_shot_Task4 += f\"\"\"\n",
    "        * Activity: {train_activity}\n",
    "          accx = {sample_data(grp['accx'].tolist(), 50)}\n",
    "          accy = {sample_data(grp['accy'].tolist(), 50)}\n",
    "          accz = {sample_data(grp['accz'].tolist(), 50)}\n",
    "        \"\"\"\n",
    "\n",
    "    query_few_shot_Task4 += f\"\"\"\n",
    "    * Analyze the accelerometer data and provide the most likely activity label for each case.\n",
    "    * PRINT ONLY A WORD WHICH IS THE PREDICTED ACTIVITY AND NOTHING ELSE NO CONTENT NO REASON JUST A PREDICTION\n",
    "\n",
    "    accx = {accx}\n",
    "    accy = {accy}\n",
    "    accz = {accz}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate model prediction (replace with actual model prediction code)\n",
    "    result = llm.invoke(query_few_shot_Task4)\n",
    "    \n",
    "    print(activity, str(result).split(\" \")[0][8:].strip(\"'\"))\n",
    "    if (activity.upper() ==str(result).split(\" \")[0][8:].strip(\"'\")):\n",
    "        i+=1\n",
    "        print(i)\n",
    "    results.append({'Subject': subject, 'Activity': activity, 'Prediction': str(result).split(\" \")[0][8:].strip(\"'\")})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV if needed\n",
    "results_df.to_csv('model_predictions_fewshot_4.1.csv', index=False)\n",
    "\n",
    "print(\"Classification complete. Results have been saved to 'model_predictions.csv'.\")\n",
    "\n",
    "print(\"accuracy\",i/18*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY FOR FEW SHOT IS 50% FOR UCI-HAR TRAINED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the Few-Shot prompting method using the data you collected to predict the activities that you performed. Adopt proper processing methods as needed. How did the model perform? **[1 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> FEW SHOT FOR TRAIN AND TEST BOTH ON THE COLLECTED DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYING LAYING\n",
      "1\n",
      "SITTING STANDING\n",
      "STANDING STANDING\n",
      "2\n",
      "WALKING WALKING_UPSTAIRS\n",
      "WALKING_DOWNSTAIRS WALKING_UPSTAIRS\n",
      "WALKING_UPSTAIRS WALKING_UPSTAIRS\n",
      "3\n",
      "LAYING LAYING\n",
      "4\n",
      "SITTING STANDING\n",
      "STANDING STANDING\n",
      "5\n",
      "WALKING WALKING_UPSTAIRS\n",
      "WALKING_DOWNSTAIRS WALKING_UPSTAIRS\n",
      "WALKING_UPSTAIRS WALKING_UPSTAIRS\n",
      "6\n",
      "Classification complete. Results have been saved to 'model_predictions.csv'.\n",
      "accuracy 50.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the test data loaded as a DataFrame\n",
    "whole_df = pd.read_csv('combined_taken_data.csv')\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "# Define the activities\n",
    "activities = ['LAYING', 'STANDING', 'WALKING', 'SITTING', 'WALKING UPSTAIRS', 'WALKING DOWNSTAIRS']\n",
    "\n",
    "def sample_data(data, sample_rate=10):\n",
    "    n=500//sample_rate\n",
    "    return data[100:n+100]\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Filter training data for specific subjects\n",
    "\n",
    "train_data_df = whole_df[whole_df[\"Subject\"] == \"LAKSH\"]\n",
    "test_data_df = whole_df[whole_df[\"Subject\"] != \"LAKSH\"]\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through each group by subject and activity\n",
    "for (subject, activity), group in test_data_df.groupby(['Subject', 'Activity']):\n",
    "    # Sample data\n",
    "    accx = sample_data(group['gFx'].tolist())\n",
    "    accy = sample_data(group['gFy'].tolist())\n",
    "    accz = sample_data(group['gFz'].tolist())\n",
    "    \n",
    "    # Create prompt for the current group\n",
    "    query_few_shot_Task4 = f\"\"\"\n",
    "    * You are a highly accurate activity classification model.\n",
    "    * Your task is to classify human activities based on the given accelerometer data.\n",
    "    * The accelerometer data is provided as mean acceleration values in the x, y, and z directions.\n",
    "    * You are given data corresponding to six different activities.\n",
    "    * The possible activities to classify are: LAYING, STANDING, WALKING, SITTING, WALKING UPSTAIRS, and WALKING DOWNSTAIRS.\"\"\"\n",
    "\n",
    "    for (train_subject, train_activity), grp in train_data_df.groupby(['Subject', 'Activity']):\n",
    "        query_few_shot_Task4 += \"\"\"Here are some examples of accelerometer data and their corresponding activities:\"\"\"\n",
    "\n",
    "        query_few_shot_Task4 += f\"\"\"\n",
    "        * Activity: {train_activity}\n",
    "          accx = {sample_data(grp['gFx'].tolist(), 50)}\n",
    "          accy = {sample_data(grp['gFy'].tolist(), 50)}\n",
    "          accz = {sample_data(grp['gFz'].tolist(), 50)}\n",
    "        \"\"\"\n",
    "    \n",
    "    query_few_shot_Task4 += f\"\"\"\n",
    "    * Analyze the accelerometer data and provide the most likely activity label for each case.\n",
    "    * PRINT ONLY A WORD WHICH IS THE PREDICTED ACTIVITY AND NOTHING ELSE NO CONTENT NO REASON JUST A PREDICTION\n",
    "\n",
    "    accx = {accx}\n",
    "    accy = {accy}\n",
    "    accz = {accz}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate model prediction (replace with actual model prediction code)\n",
    "    result = llm.invoke(query_few_shot_Task4)\n",
    "    \n",
    "    print(activity, str(result).split(\" \")[0][8:].strip(\"'\"))\n",
    "    if (activity.upper() ==str(result).split(\" \")[0][8:].strip(\"'\")):\n",
    "        i+=1\n",
    "        print(i)\n",
    "    results.append({'Subject': subject, 'Activity': activity, 'Prediction': str(result).split(\" \")[0][8:].strip(\"'\")})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV if needed\n",
    "results_df.to_csv('model_predictions_fewshot_4.2.csv', index=False)\n",
    "\n",
    "print(\"Classification complete. Results have been saved to 'model_predictions.csv'.\")\n",
    "\n",
    "print(\"accuracy\",i/12*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY IS 50% FOR BOTH TEST AND TRAIN ON THE COLLECTED DATA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
